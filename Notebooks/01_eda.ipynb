{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f34ed1",
   "metadata": {},
   "source": [
    "\n",
    "# Telecom Churn (Cease) Project — Exploratory Data Analysis\n",
    "\n",
    "This notebook performs a **business-focused EDA** for the UK Telecoms cease/churn assessment.\n",
    "\n",
    "## Business objective\n",
    "Prioritise retention effort by identifying customers most likely to **place a cease** (leave) soon, so the retention team can focus calls on higher-risk customers.\n",
    "\n",
    "## Data sources used\n",
    "- `cease` \n",
    "- `customer_info` \n",
    "- `calls` \n",
    "- `usage` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d19979",
   "metadata": {},
   "source": [
    "## 1) Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc54e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import duckdb\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab791d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f8b03d8",
   "metadata": {},
   "source": [
    "### Quick Preview of all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2443c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV preview:\n",
      "                           unique_customer_identifier event_date call_type  talk_time_seconds  hold_time_seconds\n",
      "0   aae0258b41e6e88365d7d5ce648ea69d837602b4bb419e... 2023-02-22   Loyalty              627.0              235.0\n",
      "1   15f9f6fc1872bbf6963a84de253d600e5d18d75d7784ce... 2023-03-16      Tech              267.0              293.0\n",
      "2   c18d59888cb050a5694d1e613a277d79b4a3083bd1b813... 2023-02-22   Loyalty              689.0                0.0\n",
      "3   1316da4b4282f98b572666413a71592352cc869c976212... 2023-03-16      Tech             3233.0                0.0\n",
      "4   6f33a33df6e18900a60d495eb19f2c7b238a13ec5cd894... 2023-03-16      Tech                2.0                0.0\n",
      "..                                                ...        ...       ...                ...                ...\n",
      "95  b17a215acd1cd25604e0b6732680eaf3fd15d68e9db661... 2023-03-16      Tech              424.0                0.0\n",
      "96  0e5b159902fe768b4cc1b80e211522695e8e7ebffc2ad6... 2023-03-16      Tech              944.0                0.0\n",
      "97  939c5d3ffa3378c733defa8ddc5d2b194b21d4a7edca14... 2023-02-22   Loyalty              252.0                0.0\n",
      "98  859e64e54784137bd1154933d246359a142bf033a9d106... 2023-03-16      Tech              384.0                0.0\n",
      "99  5c0f2c196012219473e2abb10b93a3514b90811a933179... 2023-03-16      Tech              609.0              187.0\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create a connection to the duckdb database\n",
    "catalog_db = duckdb.connect(\"UK_telecom.duckdb\")\n",
    "\n",
    "\n",
    "# Quick preview of calls file\n",
    "calls_csv_preview = catalog_db.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('../data/calls.csv')\n",
    "    LIMIT 100\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"CSV preview:\")\n",
    "print(calls_csv_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dade886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV preview:\n",
      "                           unique_customer_identifier cease_placed_date cease_completed_date                     reason_description reason_description_insight\n",
      "0   03b1c584533a86d067dd51bbca242db2b55b692f10d325...        2023-08-03           2023-09-04  Competitor Deals - No longer required            CompetitorDeals\n",
      "1   97a7bdce317de91a32636e6675bbb2e5b25573308ef7bb...        2023-08-03           2023-09-04                                  Cease                VagueReason\n",
      "2   c5049a1aedc36d7d7379c2c2144972b099521e6614cf8c...        2023-08-03           2023-09-05  Competitor Deals - No longer required            CompetitorDeals\n",
      "3   cffa7eecb1708776f425a0f1e70598710b5e74a66d8fea...        2023-08-03           2023-08-21                              Not Known                VagueReason\n",
      "4   f450c8a916d400b204b0228fa23bf613ceae5727e08a68...        2023-08-03           2023-09-04  Competitor Deals - No longer required            CompetitorDeals\n",
      "..                                                ...               ...                  ...                                    ...                        ...\n",
      "95  950feb95fc839c963d0e09e6c37550c33acbc85f87c1b6...        2023-08-03           2023-08-26                              Not Known                VagueReason\n",
      "96  188d40f1a731ea243aeae5e3fb3469935560846d221c8a...        2023-08-03           2023-08-10                            Bereavement                Bereavement\n",
      "97  491add2a0ee575f8626969505f74879365b095240c9133...        2023-08-03           2023-08-17                              Not Known                VagueReason\n",
      "98  bef20555ebf4bd49f78b3ee60d2b5d871a548035e95334...        2023-08-03                 null                              Not Known                VagueReason\n",
      "99  8f9e93d05a830fc4232e61cb16c11583e7f28e7244743b...        2023-08-03           2023-08-04                              Not Known                VagueReason\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create a connection to the duckdb database\n",
    "catalog_db = duckdb.connect(\"UK_telecom.duckdb\")\n",
    "\n",
    "\n",
    "# Quick preview of cease file\n",
    "cease_csv_preview = catalog_db.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('../data/cease.csv')\n",
    "    LIMIT 100\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"CSV preview:\")\n",
    "print(cease_csv_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14968be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_customer_identifier</th>\n",
       "      <th>datevalue</th>\n",
       "      <th>contract_status</th>\n",
       "      <th>contract_dd_cancels</th>\n",
       "      <th>dd_cancel_60_day</th>\n",
       "      <th>ooc_days</th>\n",
       "      <th>technology</th>\n",
       "      <th>speed</th>\n",
       "      <th>line_speed</th>\n",
       "      <th>sales_channel</th>\n",
       "      <th>crm_package_name</th>\n",
       "      <th>tenure_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7113b840dabb8224fde90ff25217acfbef4fb55a904ce1...</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>01 Early Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-464</td>\n",
       "      <td>FTTC</td>\n",
       "      <td>65</td>\n",
       "      <td>58.364000</td>\n",
       "      <td>Migrated Customer</td>\n",
       "      <td>Fibre 65 (FTTC-OR)</td>\n",
       "      <td>5608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3a04caa130b62e474c4bbcac5a3ab2dfc6002593263249...</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>02 In Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-221</td>\n",
       "      <td>FTTC</td>\n",
       "      <td>65</td>\n",
       "      <td>75.956000</td>\n",
       "      <td>Online - Ambient</td>\n",
       "      <td>Fibre 65 (FTTC-OR)</td>\n",
       "      <td>2469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>fe7be4f4d5685b5085ddfa564b35e419d2dab768380460...</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>03 Soon to be OOC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-63</td>\n",
       "      <td>FTTC</td>\n",
       "      <td>35</td>\n",
       "      <td>39.997000</td>\n",
       "      <td>Online - Affiliate</td>\n",
       "      <td>Fibre 35 (FTTC-OR)</td>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>bde98b50ca6b44cdbe4c6727a718646d2ad1c8dbc787b3...</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>02 In Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-431</td>\n",
       "      <td>FTTC</td>\n",
       "      <td>65</td>\n",
       "      <td>49.525000</td>\n",
       "      <td>Migrated Customer</td>\n",
       "      <td>Fibre 65 (FTTC-OR)</td>\n",
       "      <td>5908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>64ae1867c8fafcad80af72855af3ccd61944cffd1ff810...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>01 Early Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-715</td>\n",
       "      <td>FTTC</td>\n",
       "      <td>35</td>\n",
       "      <td>29.209584</td>\n",
       "      <td>Migrated Customer</td>\n",
       "      <td>Fibre 35 (FTTC-OR)</td>\n",
       "      <td>6815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7c3e411532d6ca0d03ff25440f56e4c72002abe6a91ba0...</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>04 Coming OOC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-17</td>\n",
       "      <td>MPF</td>\n",
       "      <td>18</td>\n",
       "      <td>14.409180</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fast Broadband</td>\n",
       "      <td>5324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>066c39e667a512aefc28a2a1326eb4ada0ab5ceaa90c87...</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>06 OOC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>FTTC</td>\n",
       "      <td>65</td>\n",
       "      <td>45.783000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fibre 65 (FTTC-OR)</td>\n",
       "      <td>5293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>35583a0190aebcc9f485feb53dd670056b1cea6a7a086f...</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>06 OOC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>FTTC</td>\n",
       "      <td>65</td>\n",
       "      <td>66.635000</td>\n",
       "      <td>Migrated Customer</td>\n",
       "      <td>Fibre 65 (FTTC-OR)</td>\n",
       "      <td>5324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>414e79d2dd18d01b238ebba5c4539cd363bed9be2d2053...</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>05 Newly OOC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>FTTC</td>\n",
       "      <td>65</td>\n",
       "      <td>79.999000</td>\n",
       "      <td>Migrated Customer</td>\n",
       "      <td>Fibre 65 (FTTC-OR)</td>\n",
       "      <td>5552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>c820d47689b6792335bfb3dee1eec3007aa5af4915fe78...</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>06 OOC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2759</td>\n",
       "      <td>MPF</td>\n",
       "      <td>18</td>\n",
       "      <td>39.806000</td>\n",
       "      <td>Migrated Customer</td>\n",
       "      <td>Plus TV Access Everything with Fibre</td>\n",
       "      <td>6229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           unique_customer_identifier  datevalue    contract_status  contract_dd_cancels  dd_cancel_60_day  ooc_days technology  speed  line_speed  \\\n",
       "90  7113b840dabb8224fde90ff25217acfbef4fb55a904ce1... 2024-06-01  01 Early Contract                    0                 0      -464       FTTC     65   58.364000   \n",
       "91  3a04caa130b62e474c4bbcac5a3ab2dfc6002593263249... 2023-11-01     02 In Contract                    0                 0      -221       FTTC     65   75.956000   \n",
       "92  fe7be4f4d5685b5085ddfa564b35e419d2dab768380460... 2023-12-01  03 Soon to be OOC                    0                 0       -63       FTTC     35   39.997000   \n",
       "93  bde98b50ca6b44cdbe4c6727a718646d2ad1c8dbc787b3... 2024-01-01     02 In Contract                    0                 0      -431       FTTC     65   49.525000   \n",
       "94  64ae1867c8fafcad80af72855af3ccd61944cffd1ff810... 2023-01-01  01 Early Contract                    0                 0      -715       FTTC     35   29.209584   \n",
       "95  7c3e411532d6ca0d03ff25440f56e4c72002abe6a91ba0... 2023-09-01      04 Coming OOC                    0                 0       -17        MPF     18   14.409180   \n",
       "96  066c39e667a512aefc28a2a1326eb4ada0ab5ceaa90c87... 2023-11-01             06 OOC                    0                 0       119       FTTC     65   45.783000   \n",
       "97  35583a0190aebcc9f485feb53dd670056b1cea6a7a086f... 2024-06-01             06 OOC                    0                 0       100       FTTC     65   66.635000   \n",
       "98  414e79d2dd18d01b238ebba5c4539cd363bed9be2d2053... 2023-03-01       05 Newly OOC                    0                 0        43       FTTC     65   79.999000   \n",
       "99  c820d47689b6792335bfb3dee1eec3007aa5af4915fe78... 2024-07-01             06 OOC                    0                 0      2759        MPF     18   39.806000   \n",
       "\n",
       "         sales_channel                      crm_package_name  tenure_days  \n",
       "90   Migrated Customer                    Fibre 65 (FTTC-OR)         5608  \n",
       "91    Online - Ambient                    Fibre 65 (FTTC-OR)         2469  \n",
       "92  Online - Affiliate                    Fibre 35 (FTTC-OR)         2353  \n",
       "93   Migrated Customer                    Fibre 65 (FTTC-OR)         5908  \n",
       "94   Migrated Customer                    Fibre 35 (FTTC-OR)         6815  \n",
       "95             Unknown                        Fast Broadband         5324  \n",
       "96             Unknown                    Fibre 65 (FTTC-OR)         5293  \n",
       "97   Migrated Customer                    Fibre 65 (FTTC-OR)         5324  \n",
       "98   Migrated Customer                    Fibre 65 (FTTC-OR)         5552  \n",
       "99   Migrated Customer  Plus TV Access Everything with Fibre         6229  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick preview of customer_info parquet file\n",
    "customer_info_preview = catalog_db.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('../data/customer_info.parquet')\n",
    "    LIMIT 100\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Parquet preview:\")\n",
    "customer_info_preview.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a38e2d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_customer_identifier</th>\n",
       "      <th>calendar_date</th>\n",
       "      <th>usage_download_mbs</th>\n",
       "      <th>usage_upload_mbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9a87ea1d3811ec1b9c78d9fd12365648ba2203508545c6...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>9860.716</td>\n",
       "      <td>1032.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d03550f4797142c2fe145fcbeb7ec247b7771b5153605d...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>3200.633</td>\n",
       "      <td>151.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ed854191c887a386f417e64bb0814ffa157d147891b070...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>3474.182</td>\n",
       "      <td>106.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ac8215f9e98d15b235e6baa5b4a45dafa930201348b23...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>16601.283</td>\n",
       "      <td>1510.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17f6b51c5295d23443a9e0736dd2209b76aba82cbef303...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>4788.412</td>\n",
       "      <td>168.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28305b0142631079c8b2fa51149867a143de44b9f303e9...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>13922.517</td>\n",
       "      <td>372.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>009496584d3f34d82d40a271a28196abe78f0a73a04050...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>10062.910</td>\n",
       "      <td>445.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6e150f4b6a34ad5b8a47d179847edc343a8286418dd92b...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>182.517</td>\n",
       "      <td>11.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0ea9eddd944adcda453338e543c36eb7a41ca203723d50...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>1624.102</td>\n",
       "      <td>81.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3489760e7b7a97af3af2fceaa7431fc6cd17e5b7b8b8e3...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>2479.076</td>\n",
       "      <td>287.534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          unique_customer_identifier calendar_date usage_download_mbs usage_upload_mbs\n",
       "0  9a87ea1d3811ec1b9c78d9fd12365648ba2203508545c6...    2022-09-22           9860.716         1032.873\n",
       "1  d03550f4797142c2fe145fcbeb7ec247b7771b5153605d...    2022-09-22           3200.633          151.137\n",
       "2  ed854191c887a386f417e64bb0814ffa157d147891b070...    2022-09-22           3474.182          106.833\n",
       "3  1ac8215f9e98d15b235e6baa5b4a45dafa930201348b23...    2022-09-22          16601.283         1510.906\n",
       "4  17f6b51c5295d23443a9e0736dd2209b76aba82cbef303...    2022-09-22           4788.412          168.129\n",
       "5  28305b0142631079c8b2fa51149867a143de44b9f303e9...    2022-09-22          13922.517          372.234\n",
       "6  009496584d3f34d82d40a271a28196abe78f0a73a04050...    2022-09-22          10062.910          445.010\n",
       "7  6e150f4b6a34ad5b8a47d179847edc343a8286418dd92b...    2022-09-22            182.517           11.934\n",
       "8  0ea9eddd944adcda453338e543c36eb7a41ca203723d50...    2022-09-22           1624.102           81.300\n",
       "9  3489760e7b7a97af3af2fceaa7431fc6cd17e5b7b8b8e3...    2022-09-22           2479.076          287.534"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick preview of usage parquet file\n",
    "usage_preview = catalog_db.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('../data/usage.parquet')\n",
    "    LIMIT 100\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Parquet preview:\")\n",
    "usage_preview.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a59f0",
   "metadata": {},
   "source": [
    " #### Dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3da9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing current working directory\n",
    "cwd = Path.cwd()\n",
    "repo_dir = cwd.parent if cwd.name.lower() in {\"notebook\", \"notebooks\"} else cwd\n",
    "\n",
    "# Default project data paths (edit if your names differ)\n",
    "data_dir = repo_dir / \"data\"\n",
    "cease_path = data_dir / \"cease.csv\"\n",
    "calls_path = data_dir / \"calls.csv\"\n",
    "customer_path = data_dir / \"customer_info.parquet\"\n",
    "usage_path = data_dir / \"usage.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf5fb6f",
   "metadata": {},
   "source": [
    "#### Load Datasets \n",
    "#### The datasets provided for this project vary in format and size. To minimize memory overhead during exploratory data analysis, DuckDB was used so queries could be executed directly against the source files without loading entire datasets into Python objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d03a68",
   "metadata": {},
   "source": [
    "#### Call & Cease dataset (csv formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e27e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CSV robustly into pandas + register a DuckDB view.\"\"\"\n",
    "def load_table(path:Path, table_name:str, catalog_db:duckdb.DuckDBPyConnection):\n",
    "    \"\"\"Load CSV/Parquet robustly into pandas + register a DuckDB view.\"\"\"\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix == \".csv\":\n",
    "        df = catalog_db.execute(f\"\"\"\n",
    "            SELECT *\n",
    "            FROM read_csv_auto('{path.as_posix()}')\n",
    "        \"\"\").df()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type for {path}\")\n",
    "    \n",
    "    \n",
    "    #register dataset and view for SQL exploration\n",
    "    catalog_db.register(f\"{table_name}_df\", df)\n",
    "    catalog_db.execute(f\"CREATE OR REPLACE VIEW {table_name} AS SELECT * FROM {table_name}_df\")\n",
    "    return df    \n",
    "\n",
    "\n",
    "def parse_dates_if_present(df: pd.DataFrame):\n",
    "    date_like =[c for c in df.columns if \"date\" in c.lower() or \"time\" in c.lower()]\n",
    "    for c in date_like:\n",
    "        df[c] = pd.to_datetime(df[c], errors='coerce')\n",
    "    return df\n",
    "\n",
    "cease = parse_dates_if_present(load_table(cease_path, \"cease\", catalog_db))\n",
    "calls = parse_dates_if_present(load_table(calls_path, \"calls\", catalog_db))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065c8fb",
   "metadata": {},
   "source": [
    "### Data Quality Checks (EDA Foundation)\n",
    "(a) Cease | Calls dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0feefe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "cease   : (146363, 5)\n",
      "calls   : (628437, 5)\n",
      "***************************************************************\n",
      "info for cease datasets\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 146363 entries, 0 to 146362\n",
      "Data columns (total 5 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   unique_customer_identifier  146363 non-null  str           \n",
      " 1   cease_placed_date           146363 non-null  datetime64[us]\n",
      " 2   cease_completed_date        119146 non-null  datetime64[us]\n",
      " 3   reason_description          146363 non-null  str           \n",
      " 4   reason_description_insight  146363 non-null  str           \n",
      "dtypes: datetime64[us](2), str(3)\n",
      "memory usage: 19.2 MB\n",
      "***************************************************************\n",
      "info for calls datasets\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 628437 entries, 0 to 628436\n",
      "Data columns (total 5 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   unique_customer_identifier  628437 non-null  str           \n",
      " 1   event_date                  628437 non-null  datetime64[us]\n",
      " 2   call_type                   628437 non-null  str           \n",
      " 3   talk_time_seconds           628437 non-null  datetime64[ns]\n",
      " 4   hold_time_seconds           628437 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), datetime64[us](1), str(2)\n",
      "memory usage: 66.0 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes:\")\n",
    "print(\"cease   :\", cease.shape)\n",
    "print(\"calls   :\", calls.shape)\n",
    "\n",
    "print(f\"***************************************************************\")\n",
    "\n",
    "print(f\"info for cease datasets\")\n",
    "cease.info()\n",
    "\n",
    "print(f\"***************************************************************\")\n",
    "print(f\"info for calls datasets\")\n",
    "calls.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2518e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calls_row_duplicates</td>\n",
       "      <td>6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cease_row_duplicates</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calls_dup_customer_date</td>\n",
       "      <td>269110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     check   value\n",
       "0     calls_row_duplicates    6486\n",
       "1     cease_row_duplicates     350\n",
       "2  calls_dup_customer_date  269110"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Duplicate checks (record-level and key-level)\n",
    "checks = {\n",
    "    'calls_row_duplicates': calls.duplicated().sum(),\n",
    "    'cease_row_duplicates': cease.duplicated().sum(),\n",
    "    'calls_dup_customer_date': calls.duplicated(['unique_customer_identifier','event_date']).sum(),\n",
    "}\n",
    "pd.DataFrame(list(checks.items()), columns=['check','value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c57a23",
   "metadata": {},
   "source": [
    "### \n",
    "\n",
    "*****************************************************************\n",
    "#### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f320ca4",
   "metadata": {},
   "source": [
    "<b> Cease Dataset </b>\n",
    "\n",
    "- 146,363 rows, 5 columns; suitable for event-level churn/cease analysis.\n",
    "\n",
    "- Strong data quality: all key fields are complete except cease_completed_date (27,217 missing).\n",
    "\n",
    "- Missing cease_completed_date may carry business meaning (e.g., pending/incomplete ceases) and should be investigated.\n",
    "\n",
    "- cease_placed_date is the main field for defining the churn/cease target window.\n",
    "\n",
    "- reason_description and reason_description_insight are useful for churn reason segmentation and explainability.\n",
    "\n",
    "<b> Cease Dataset : Duplicates </b>\n",
    "- cease_row_duplicates = 350\n",
    "\n",
    "- There are 350 fully duplicated rows in the cease dataset.\n",
    "\n",
    "- Same issue: exact duplicate records.\n",
    "\n",
    "- Risk: can inflate cease counts and distort target creation if not removed.\n",
    "\n",
    "<b> Calls Dataset </b>\n",
    "\n",
    "- 628,437 rows, 5 columns; key dataset for customer interaction/behaviour features.\n",
    "\n",
    "- High completeness across fields (no visible missing values).\n",
    "\n",
    "- talk_time_seconds and hold_time_seconds appear to be stored as datetime, not numeric durations — this needs correction before feature engineering.\n",
    "\n",
    "- Well suited for building rolling behavioural features (e.g., call volume, repeat calls, hold-time metrics, retention/loyalty contact patterns).\n",
    "\n",
    "<b>Calls Dataset : Duplicates </b>\n",
    "- calls_row_duplicates = 6,486\n",
    "\n",
    "- There are 6,486 fully duplicated rows in the calls dataset.\n",
    "\n",
    "- This means all columns in those rows are identical copies of another row.\n",
    "\n",
    "- Risk: double-counting call events, inflated call volumes, biased features (e.g., call frequency, hold time totals).\n",
    "\n",
    "\n",
    "\n",
    "<b> Modelling Readiness (Overall) </b>\n",
    "\n",
    "- Both datasets are strong foundations for churn modelling with clear identifiers and high completeness.\n",
    "\n",
    "- Cease data supports target creation and churn reason analysis.\n",
    "\n",
    "- Calls data provides valuable behavioural signals but requires duration field type conversion.\n",
    "\n",
    "- Together, they support a robust cease-risk prediction and retention prioritisation workflow.\n",
    "\n",
    "- Exact row duplicates (calls_row_duplicates, cease_row_duplicates) should usually be removed.\n",
    "\n",
    "- Customer-date duplicates should be investigated before removal, because they may represent valid multiple same-day interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7044f",
   "metadata": {},
   "source": [
    "### \n",
    "\n",
    "\n",
    "\n",
    "***************************************************\n",
    "(b) Customer info | usage dataset (Large Parquet files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba4a1097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "File: customer_info.parquet\n",
      "Rows: 3,545,538 | Columns: 12\n",
      "File size (disk): 257.54 MB\n",
      "--------------------------------------------------------------------------------\n",
      "               column_name  non_null_count  null_count  null_pct   dtype\n",
      "unique_customer_identifier         3545538           0      0.00 VARCHAR\n",
      "                 datevalue         3545538           0      0.00    DATE\n",
      "           contract_status         3545538           0      0.00 VARCHAR\n",
      "       contract_dd_cancels         3545538           0      0.00  BIGINT\n",
      "          dd_cancel_60_day         3545538           0      0.00 INTEGER\n",
      "                  ooc_days         3526590       18948      0.53 INTEGER\n",
      "                technology         3545538           0      0.00 VARCHAR\n",
      "                     speed         3545538           0      0.00 INTEGER\n",
      "                line_speed         3545538           0      0.00  DOUBLE\n",
      "             sales_channel         3545538           0      0.00 VARCHAR\n",
      "          crm_package_name         3545538           0      0.00 VARCHAR\n",
      "               tenure_days         3545538           0      0.00 INTEGER\n",
      "\n",
      "================================================================================\n",
      "File: usage.parquet\n",
      "Rows: 83,185,050 | Columns: 4\n",
      "File size (disk): 2951.04 MB\n",
      "--------------------------------------------------------------------------------\n",
      "               column_name  non_null_count  null_count  null_pct   dtype\n",
      "unique_customer_identifier        83185050           0       0.0 VARCHAR\n",
      "             calendar_date        83185050           0       0.0    DATE\n",
      "        usage_download_mbs        83185050           0       0.0 VARCHAR\n",
      "          usage_upload_mbs        83185050           0       0.0 VARCHAR\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_dir = Path(\"../data\")\n",
    "parquet_files = list(data_dir.glob(\"*.parquet\"))\n",
    "\n",
    "for file_path in parquet_files:\n",
    "    file_str = file_path.as_posix()\n",
    "\n",
    "    # Shape\n",
    "    row_count = catalog_db.execute(f\"\"\"\n",
    "        SELECT COUNT(*) AS n_rows\n",
    "        FROM read_parquet('{file_str}')\n",
    "    \"\"\").fetchone()[0]\n",
    "\n",
    "    schema_df = catalog_db.execute(f\"\"\"\n",
    "        DESCRIBE SELECT * FROM read_parquet('{file_str}')\n",
    "    \"\"\").df()\n",
    "\n",
    "    col_count = len(schema_df)\n",
    "\n",
    "    # Build non-null / null report per column\n",
    "    info_rows = []\n",
    "    for col in schema_df[\"column_name\"].tolist():\n",
    "        non_null_count = catalog_db.execute(f'''\n",
    "            SELECT COUNT(\"{col}\") \n",
    "            FROM read_parquet('{file_str}')\n",
    "        ''').fetchone()[0]\n",
    "\n",
    "        null_count = row_count - non_null_count\n",
    "        null_pct = (null_count / row_count * 100) if row_count else 0\n",
    "\n",
    "        col_type = schema_df.loc[schema_df[\"column_name\"] == col, \"column_type\"].iloc[0]\n",
    "\n",
    "        info_rows.append({\n",
    "            \"column_name\": col,\n",
    "            \"non_null_count\": int(non_null_count),\n",
    "            \"null_count\": int(null_count),\n",
    "            \"null_pct\": round(null_pct, 2),\n",
    "            \"dtype\": col_type\n",
    "        })\n",
    "\n",
    "    info_df = pd.DataFrame(info_rows)\n",
    "\n",
    "    # File size (parquet file size on disk)\n",
    "    file_size_mb = file_path.stat().st_size / (1024 ** 2)\n",
    "\n",
    "    # Print summary (.info()-like)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"File: {file_path.name}\")\n",
    "    print(f\"Rows: {row_count:,} | Columns: {col_count}\")\n",
    "    print(f\"File size (disk): {file_size_mb:.2f} MB\")\n",
    "    print(\"-\" * 80)\n",
    "    print(info_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7db883",
   "metadata": {},
   "source": [
    "### \n",
    "\n",
    "*****************************************************************\n",
    "#### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157691d4",
   "metadata": {},
   "source": [
    "Key Observations\n",
    "<b> customer_info.parquet </b>\n",
    "\n",
    "- Large, high-quality snapshot dataset: 3,545,538 rows × 12 columns (257.54 MB), suitable as the main monthly snapshot table for churn modelling.\n",
    "\n",
    "- Very strong completeness: 11/12 columns are fully populated.\n",
    "\n",
    "- Minor missingness: ooc_days has 0.53% nulls (18,948 rows) — low impact, but should be reviewed and handled.\n",
    "\n",
    "- Strong churn features present: datevalue (snapshot date), contract_status, contract_dd_cancels, dd_cancel_60_day, ooc_days, tenure_days, plus package/channel/service fields.\n",
    "\n",
    "- Data types are mostly modelling-ready for feature engineering.\n",
    "\n",
    "<b> usage.parquet </b>\n",
    "\n",
    "- Very large behavioural dataset: 83,185,050 rows × 4 columns (~2.95 GB), ideal for usage trend and churn-signal engineering.\n",
    "\n",
    "- Excellent completeness: all columns are 100% populated.\n",
    "\n",
    "- calendar_date is correctly typed as DATE, enabling rolling-window features (e.g., 7/30/90-day usage).\n",
    "\n",
    "- Key preprocessing issue: usage_download_mbs and usage_upload_mbs are stored as VARCHAR and must be converted to numeric before analysis/modeling.\n",
    "\n",
    "- Best handled with DuckDB (or similar) for memory-efficient EDA and aggregations.\n",
    "\n",
    "<b> Overall Data Readiness </b> \n",
    "\n",
    "- Data quality is strong overall and suitable for a robust churn/cease modelling workflow.\n",
    "\n",
    "- Main preprocessing priorities:\n",
    "\n",
    "- Handle missing values in ooc_days\n",
    "\n",
    "- Convert usage fields from VARCHAR to numeric\n",
    "\n",
    "<b> Modelling roles: </b> \n",
    "\n",
    "- customer_info = snapshot anchor dataset\n",
    "\n",
    "- usage = behavioural feature source (trend/decline/volatility signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d903ab67",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
